{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AdamW, BertForSequenceClassification\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "from pytorch_transformers import WarmupLinearSchedule\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from pytorch_pretrained_bert import BertAdam\n",
    "import torch\n",
    "from torch import tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "from pprint import pprint\n",
    "from tabulate import tabulate\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import warnings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>generally_bad_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stitch Fix said it ended the quarter with abou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only two of the murder cases have made it to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>*FDA Requests Meeting With Walgreens Corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mr. Powell said Fed officials are near agreeme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the few days since former Deputy Commission...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  generally_bad_score\n",
       "0  Stitch Fix said it ended the quarter with abou...                    1\n",
       "1  Only two of the murder cases have made it to t...                    0\n",
       "2  *FDA Requests Meeting With Walgreens Corporate...                    1\n",
       "3  Mr. Powell said Fed officials are near agreeme...                    1\n",
       "4  In the few days since former Deputy Commission...                    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('file.csv')\n",
    "df = df.rename(columns={'article':'body'})\n",
    "df.generally_bad_score = df.generally_bad_score.apply(lambda x: 1 if x > 2 else 0)\n",
    "# Convert from float to int\n",
    "# df.generally_bad_score = df.generally_bad_score.astype('float')\n",
    "# pd.options.display.float_format = '{:,.0f}'.format\n",
    "df = df.drop(['article_id', 'title'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.body = df.body.str.lower()\n",
    "df.body = df.body.str.translate(str.maketrans('', '', string.digits))\n",
    "df.body = df.body.str.translate(str.maketrans('', '', string.punctuation))\n",
    "df.body = df.body.str.replace('bedandbreakfast', 'bed and breakfast')\n",
    "df.body = df.body.str.replace('yearold', 'year old')\n",
    "df.body = df.body.str.replace('obama—who', 'obama who')\n",
    "df.body = df.body.str.replace('friendofthecourt', 'friend of the court')\n",
    "df.body = df.body.str.replace('chicago—to', 'chicago to')\n",
    "df.body = df.body.str.replace('way…to', 'way to')\n",
    "df.body = df.body.str.replace('-', '')\n",
    "df.body = df.body.str.replace('said—that', 'said that')\n",
    "df.body = df.body.str.replace('firstdegree', 'first degree')\n",
    "df.body = df.body.str.replace('andmark', 'and mark')\n",
    "df.body = df.body.str.replace('seconddegree', 'second degree')\n",
    "df.body = df.body.str.replace('mutiple', 'multiple')\n",
    "df.body = df.body.str.replace('sevenpage', 'seven page')\n",
    "df.body = df.body.str.replace('centerpiece', 'center piece')\n",
    "df.body = [re.sub(' +', ' ', x) for x in df.body]\n",
    "stop = stopwords.words('english')\n",
    "df.body = df.body.str.split()\n",
    "df.body = df.body.apply(lambda x: [item for item in x if item not in stop])\n",
    "df.body = [' '.join(i) for i in df.body]\n",
    "temp = df.body\n",
    "df.body = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in df.body]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'stitch', 'fix', 'said', 'ended', 'quarter', 'million', 'active', 'clients', 'period', 'year', 'earlier', 'revenue', 'per', 'active', 'client', 'also', 'grew', 'year', 'ago', 'active', 'clients', 'received', 'shipment', 'past', 'year', 'stitch', 'fix', 'shares', 'gained', 'year', 'also', 'posted', 'similar', 'gains', 'company', '##s', 'second', '##qua', '##rter', 'report', 'march', 'earnings', 'beating', 'internal', 'analyst', 'forecast', '##s', 'however', 'higher', 'selling', 'administrative', 'costs', 'weighed', 'company', '##s', 'profit', 'latest', 'period', 'result', 'still', 'better', 'analysts', 'expected', 'profit', 'fell', 'million', 'cents', 'share', 'company', 'warned', 'march', 'marketing', 'spending', 'costs', 'tied', 'expansion', 'uk', 'would', 'hurt', 'third', '##qua', '##rter', 'profit', 'katrina', 'lake', 'stitch', 'fix', '##s', 'chief', 'executive', 'said', 'conference', 'call', 'analysts', 'company', 'completed', 'launch', 'last', 'month', 'early', 'tell', 'many', 'new', 'clients', 'could', 'add', 'expansion', 'stitch', 'fix', 'raised', 'revenue', 'forecast', 'year', 'billion', 'billion', 'previous', 'outlook', 'billion', 'billion', 'financial', 'chief', 'paul', 'ye', '##e', 'said', 'call', 'fourth', '##qua', '##rter', 'revenue', 'would', 'million', 'million', 'would', 'gain', 'year', '##ear', '##lier', 'period', 'results', 'reflect', 'continued', 'execution', 'across', 'three', 'growth', 'pillars', 'expanding', 'relationships', 'existing', 'clients', 'attracting', 'new', 'clients', 'growing', 'market', 'opportunity', 'ms', 'lake', 'said', 'write', 'patrick', 'thomas', 'patrick', '##th', '##oma', '##sw', '##s', '##j', '##com', '[SEP]']\n",
      "CPU times: user 11.8 s, sys: 67.1 ms, total: 11.9 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in df.body]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcea434bd584abf9b5eb1ad9406918d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1033), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids=[]\n",
    "for i in tqdm_notebook(range(len(tokenized_texts))):\n",
    "    input_ids.append(tokenizer.convert_tokens_to_ids(tokenized_texts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, df.generally_bad_score, random_state=56, test_size=0.2)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,random_state=56, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels.values)\n",
    "validation_labels = torch.tensor(validation_labels.values)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device ='cpu'\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "max_grad_norm = 1.0\n",
    "num_total_steps = 1000\n",
    "num_warmup_steps = 100\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_total_steps)  # 0.1\n",
    "\n",
    "### In PyTorch-Transformers, optimizer and schedules are splitted and instantiated like this:\n",
    "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=num_warmup_steps, t_total=num_total_steps)  # PyTorch scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370754257f9d4cb3887fead6ffbb9498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [1/52], Loss: 0.5966\n",
      "Epoch [1/2], Step [51/52], Loss: 0.7106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Step [1/52], Loss: 0.4790\n",
      "Epoch [2/2], Step [51/52], Loss: 0.3789\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_dataloader)\n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for epoch in tqdm_notebook(range(epochs)):\n",
    "\n",
    "    # Training\n",
    "    # Set our model to training mode (as opposed to evaluation mode)\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "    # Train the data for one epoch\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        train_loss_set.append(loss.item())    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if (i) % 50 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, epochs, i+1, total_step, loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.getcwd()+'/model_without_language_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, batch in enumerate(validation_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        # print (outputs)\n",
    "        prediction = torch.argmax(outputs[0],dim=1)\n",
    "        total += b_labels.size(0)\n",
    "        correct+=(prediction==b_labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on val data is: 0.6590909090909092 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         4\n",
      "           1       0.82      0.82      0.82        11\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.66      0.66      0.66        15\n",
      "weighted avg       0.73      0.73      0.73        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy of the model on val data is: {} %'.format(roc_auc_score(b_labels, prediction)))\n",
    "print('{}'.format(classification_report(b_labels, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = keras.callbacks.ModelCheckpoint(os.getcwd()+\"/model_without_language_model.ckpt\", save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This might be useful not sure yet though**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37553 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(temp.values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ends here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(temp.values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "Y = pd.get_dummies(df.generally_bad_score).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(X, Y, test_size=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the model that gave the best result so far, but have only tested LSTM RNN and didn't fully tune this model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "# model.add(SpatialDropout1D(0.2))\n",
    "# model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(6, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ends here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/cheungjoey/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 660 samples, validate on 166 samples\n",
      "Epoch 1/5\n",
      "660/660 [==============================] - 0s 652us/step - loss: 2633.3125 - accuracy: 0.5682 - val_loss: 1847.9222 - val_accuracy: 0.7349\n",
      "Epoch 2/5\n",
      "660/660 [==============================] - 0s 43us/step - loss: 1731.9399 - accuracy: 0.7515 - val_loss: 1534.0898 - val_accuracy: 0.7229\n",
      "Epoch 3/5\n",
      "660/660 [==============================] - 0s 45us/step - loss: 1233.9616 - accuracy: 0.7273 - val_loss: 1272.5701 - val_accuracy: 0.6506\n",
      "Epoch 4/5\n",
      "660/660 [==============================] - 0s 45us/step - loss: 933.5868 - accuracy: 0.6939 - val_loss: 988.2179 - val_accuracy: 0.6566\n",
      "Epoch 5/5\n",
      "660/660 [==============================] - 0s 40us/step - loss: 678.5280 - accuracy: 0.7030 - val_loss: 738.3949 - val_accuracy: 0.6867\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=250, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(train_features, train_labels, epochs=5, batch_size=64,validation_split=0.2, callbacks=[saver])\n",
    "# Final evaluation of the model\n",
    "model_pred_train = model.predict(train_features)\n",
    "model_pred_test = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a940cb438>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a94ce9748>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x1a940e2d68>,\n",
       " <matplotlib.axis.XTick at 0x1a940e26a0>,\n",
       " <matplotlib.axis.XTick at 0x1a940e2550>,\n",
       " <matplotlib.axis.XTick at 0x1a94cfe198>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.YTick at 0x1a940f9ac8>,\n",
       " <matplotlib.axis.YTick at 0x1a940f9400>,\n",
       " <matplotlib.axis.YTick at 0x1a4ed0e198>,\n",
       " <matplotlib.axis.YTick at 0x1a94cfe668>,\n",
       " <matplotlib.axis.YTick at 0x1a94cfed30>,\n",
       " <matplotlib.axis.YTick at 0x1a94d024e0>,\n",
       " <matplotlib.axis.YTick at 0x1a94d029b0>,\n",
       " <matplotlib.axis.YTick at 0x1a94d02e80>,\n",
       " <matplotlib.axis.YTick at 0x1a94d02908>,\n",
       " <matplotlib.axis.YTick at 0x1a94cfebe0>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a94ce9f98>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a94d0a240>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x1a94cc5e80>,\n",
       " <matplotlib.axis.XTick at 0x1a94cc57b8>,\n",
       " <matplotlib.axis.XTick at 0x1a94cc54e0>,\n",
       " <matplotlib.axis.XTick at 0x1a94d0aeb8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, 5, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, 5, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Recurrent Neural Network baseline: 0.5320801053217883\n",
      "LSTM Recurrent Neural Network: 0.4455409356725146\n",
      "LSTM Recurrent Neural Network baseline:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.25      0.23       145\n",
      "           1       0.84      0.81      0.82       681\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       826\n",
      "   macro avg       0.53      0.53      0.53       826\n",
      "weighted avg       0.73      0.71      0.72       826\n",
      " samples avg       0.71      0.71      0.71       826\n",
      "\n",
      "LSTM Recurrent Neural Network:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.14      0.12        36\n",
      "           1       0.81      0.76      0.78       171\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       207\n",
      "   macro avg       0.46      0.45      0.45       207\n",
      "weighted avg       0.69      0.65      0.67       207\n",
      " samples avg       0.65      0.65      0.65       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LSTM Recurrent Neural Network baseline: ' + str(roc_auc_score(train_labels, model_pred_train)))\n",
    "print('LSTM Recurrent Neural Network: ' + str(roc_auc_score(test_labels, model_pred_test)))\n",
    "# Not sure if this last part for classification report is correct or not (Found by the Chinese)\n",
    "for i in range(len(model_pred_train)):\n",
    "    max_value=max(model_pred_train[i])\n",
    "    for j in range(len(model_pred_train[i])):\n",
    "        if max_value==model_pred_train[i][j]:\n",
    "            model_pred_train[i][j]=1\n",
    "        else:\n",
    "            model_pred_train[i][j]=0\n",
    "                \n",
    "for i in range(len(model_pred_test)):\n",
    "    max_value=max(model_pred_test[i])\n",
    "    for j in range(len(model_pred_test[i])):\n",
    "        if max_value==model_pred_test[i][j]:\n",
    "            model_pred_test[i][j]=1\n",
    "        else:\n",
    "            model_pred_test[i][j]=0\n",
    "print('LSTM Recurrent Neural Network baseline:\\n\\n ' + str(classification_report(train_labels, model_pred_train)))\n",
    "print('LSTM Recurrent Neural Network:\\n\\n ' + str(classification_report(test_labels, model_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   16.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.750605 using {}\n",
      "0.750605 (0.011494) with: {}\n"
     ]
    }
   ],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=250, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0, epochs=100, batch_size=10)\n",
    "# define the grid search parameters\n",
    "param_grid = {\n",
    "#     'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "#     'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "#     'epochs': [10, 50, 100],\n",
    "#     'learn_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "#     'momentum': [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
    "#     'init_mode': ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],\n",
    "#     'activation': ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "#     'weight_constraint': [1, 2, 3, 4, 5],\n",
    "#     'dropout_rate': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "#     'neurons': [1, 5, 10, 15, 20, 25, 30]\n",
    "    \n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                      cv = 3, n_jobs = -1, verbose = 2, return_train_score=True)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_result = grid_search.fit(train_features, train_labels);\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possibly add Precision_Recall_Curve and ROC_Curve and do feature selection with Tree model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
